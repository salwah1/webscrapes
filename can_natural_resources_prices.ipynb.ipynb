{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095ea648-2122-491d-8378-a99e6797b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbdce0d-927f-4548-9271-854ecfbc1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL of the webpage with the table\n",
    "url = \"https://natural-resources.canada.ca/our-natural-resources/energy-sources-distribution/fossil-fuels/crude-oil/oil-pricing/18087#cop\"\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1dc146-d6b6-42f2-b8d7-6d5f8e5b6ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad46001d-3c31-496d-b575-4f24fe18b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object and specify the parser\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd195b52-a740-4cd8-8f1c-880d1a280456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to find the dates witin the links: these are the 2 strings that border the date string\n",
    "sub_link=\"/crude-oil/oil-pricing/selected-crude-oil-prices-\"\n",
    "sub_link2=\"-canadian-dollars-cubic-metre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55560cef-aee0-4283-8f45-81c615f28141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list that has all the links\n",
    "all_links=[]\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    href=link.get('href')\n",
    "    if sub_link in href:\n",
    "      all_links.append(href)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5468f54-62c2-43d8-8ed1-6e31d301606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list that has all the dates\n",
    "dates=[]\n",
    "for i in range(len(all_links)):\n",
    "    x=0\n",
    "    y=0\n",
    "    x=all_links[i].find(sub_link)\n",
    "    y=all_links[i].find(sub_link2)\n",
    "    x=x+len(sub_link)\n",
    "    \n",
    "    new_link=all_links[i][x:y]\n",
    "    dates.append(new_link)\n",
    "    \n",
    "    \n",
    "\n",
    "# better methods potentially:\n",
    "    ##use enumerate instead\n",
    "    ## use split  string.split\n",
    "    ## regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c449a4fb-a9e4-46d6-9431-81685fbf13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the input list by formatting each date using the strptime() function\n",
    "try:\n",
    "    dates.sort(key=lambda date: datetime.strptime(date, \"%B-%Y\"))\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c53cb8-36ca-4970-b9c4-1fb44e5f30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting 2 months worth of data just in case\n",
    "latest_date=dates[0]\n",
    "second_latest_date=dates[1]\n",
    "target_link=''\n",
    "last_month_link=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b2bd95-d516-4936-b8de-1e7f1aba196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i  in range(len(all_links)):  \n",
    "    if latest_date in all_links[i]:\n",
    "        target_link=all_links[i]\n",
    "        #last_month_link=all_links[i+1]\n",
    "    if second_latest_date in all_links[i]:\n",
    "        last_month_link=all_links[i]\n",
    "    if target_link and  last_month_link:\n",
    "        break\n",
    "  # once target link and last month link is found, for loop breaks      \n",
    "# use regex to be more specific find dates within the 2 strings only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a86fc8c-d7d4-409d-ac4f-35ccbb9c3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the latest data\n",
    "response1 = requests.get(target_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38526d5d-0334-4bf8-b831-b3a76b1e0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the latest-1 data\n",
    "response2 = requests.get(last_month_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f9bdad6-2389-431b-9aed-b7fccdbcd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup objects and specify the parser\n",
    "\n",
    "soup1 = BeautifulSoup(response1.content, \"html.parser\")\n",
    "# Find the table element based on its HTML class (e.g., <table class=\"data-table\">)\n",
    "table1 = soup1.find(\"table\", class_=\"table-bordered\")\n",
    "\n",
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")\n",
    "# Find the table element based on its HTML class (e.g., <table class=\"data-table\">)\n",
    "table2 = soup2.find(\"table\", class_=\"table-bordered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d61a865-0519-4821-8964-66579994afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check if the table exists\n",
    "if table1 and table2:\n",
    "    # Extract table headers (assuming they are in <th> tags)\n",
    "    headers1 = [header.text.strip() for header in table1.find_all(\"th\")]\n",
    "    headers2 = [header.text.strip() for header in table2.find_all(\"th\")]\n",
    "\n",
    "    # Extract table rows (assuming they are in <tr> tags)\n",
    "    rows1 = []\n",
    "    rows2 = []\n",
    "    for row in table1.find_all(\"tr\"):\n",
    "        # Extract the data cells for each row (assuming they are in <td> tags)\n",
    "        cells = [cell.text.strip() for cell in row.find_all(\"td\")]\n",
    "        rows1.append(cells)\n",
    "        \n",
    "  #same for second table:      \n",
    "      \n",
    "    for row in table2.find_all(\"tr\"):\n",
    "        # Extract the data cells for each row (assuming they are in <td> tags)\n",
    "        cells = [cell.text.strip() for cell in row.find_all(\"td\")]\n",
    "        rows2.append(cells)\n",
    "\n",
    " \n",
    "\n",
    "    # Create a pandas DataFrames\n",
    "    df1 = pd.DataFrame(rows1, columns=headers1)\n",
    "    df2= pd.DataFrame(rows2, columns=headers2)\n",
    "\n",
    "else:\n",
    "    print(\"Tables not found on the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2afc4be8-5ba9-4b9f-b831-1662f3e002d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = df1.columns.str.replace('\\n', '')\n",
    "df2.columns = df2.columns.str.replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea6f80-ae9f-459c-af48-4656f5821267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
